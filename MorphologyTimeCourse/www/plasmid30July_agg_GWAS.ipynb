{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getKmers(sequence, size, step): \n",
    "    output_seq=[]\n",
    "    for x in range(0, len(sequence) - size, step):\n",
    "        output_seq.append(sequence[x:x+size])\n",
    "    return(output_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    #    \"loss\":[\"deviance\"],\n",
    "    #\"learning_rate\": [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n",
    "    #\"min_samples_split\": np.linspace(0.1, 0.5, 12),\n",
    "    #\"min_samples_leaf\": np.linspace(0.1, 0.5, 12),\n",
    "        \"max_depth\":[1,3,5],\n",
    "    #\"max_features\":[\"log2\",\"sqrt\"],\n",
    "    #\"criterion\": [\"friedman_mse\",  \"mae\"],\n",
    "        \"subsample\":[ 0.8, 1.0],\n",
    "        \"n_estimators\":[5,10]\n",
    "            }\n",
    "\n",
    "clf = GridSearchCV(GradientBoostingRegressor(), parameters, cv=3, n_jobs=-1)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.best_params_)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "unique_sequences_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imporatnce=pd.DataFrame({\"un\":unique_sequences, \"importance\":clf.best_estimator_.feature_importances_})\n",
    "df_imporatnce=df_imporatnce.loc[df_imporatnce['importance'] > 0]\n",
    "df_imporatnce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as mp\n",
    "from numpy import absolute\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "result_f=[]\n",
    "label_index=2\n",
    "for k in range(2,4):\n",
    "    import pandas as pd\n",
    "    df_input=pd.read_csv(\"/Users/moradigd/Documents/Plasmid/input_agg.csv\")\n",
    "    df_input.columns\n",
    "    df_input=df_input.iloc[:,[0,k]]\n",
    "    df_input.shape\n",
    "    df_input=df_input.dropna()\n",
    "    df_input=df_input.reset_index()\n",
    "\n",
    "     \n",
    "    for g in range(9,10):\n",
    "        \n",
    "        print(\"start\")\n",
    "        unique_sequences_set=[]\n",
    "#for i in range(len(df_input['seq'])):\n",
    "\n",
    "        for i in range(df_input.shape[0]):\n",
    "            print(i)\n",
    "            unique_sequences_set=unique_sequences_set+getKmers(df_input['seq'][i], g, 1)\n",
    "        unique_sequences=list(set(unique_sequences_set))\n",
    "\n",
    "        print(\"done\")\n",
    "#\"abcdabcva\".count(\"ab\")\n",
    "#df_input['seq'][1].count(unique_sequences[1])\n",
    "\n",
    "        [df_input['seq'][1].count(i) for i in unique_sequences]\n",
    "        \n",
    "        print(\"start\")\n",
    "        unique_sequences_freq=[]\n",
    "#for i in range(len(df_input['seq'])):\n",
    "        for j in range(df_input.shape[0]):\n",
    "            print(j)\n",
    "            unique_sequences_freq.append([df_input['seq'][j].count(i) for i in unique_sequences])\n",
    "        unique_sequences_freq   \n",
    "        unique_sequences_freq=pd.DataFrame(unique_sequences_freq)\n",
    "#unique_sequences_freq.columns=unique_sequences\n",
    "        unique_sequences_freq\n",
    "        print(\"done\")\n",
    "\n",
    "\n",
    "        unique_sequences_freq[['label']]=df_input.iloc[0:df_input.shape[0],label_index]\n",
    "        unique_sequences_freq\n",
    "        \n",
    "        scaler = MinMaxScaler()\n",
    "        unique_sequences_freq = pd.DataFrame(scaler.fit_transform(unique_sequences_freq), columns=unique_sequences_freq.columns)\n",
    "\n",
    "        data=unique_sequences_freq.values\n",
    "\n",
    "        X, y = data[:, :-1], data[:, -1]\n",
    "        \n",
    "        \n",
    "        for m in range(10):\n",
    "        \n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "    \n",
    "            parameters = {\n",
    "    #    \"loss\":[\"deviance\"],\n",
    "    #\"learning_rate\": [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n",
    "    #\"min_samples_split\": np.linspace(0.1, 0.5, 12),\n",
    "    #\"min_samples_leaf\": np.linspace(0.1, 0.5, 12),\n",
    "        \"max_depth\":[1,3,5],\n",
    "    #\"max_features\":[\"log2\",\"sqrt\"],\n",
    "    #\"criterion\": [\"friedman_mse\",  \"mae\"],\n",
    "        \"subsample\":[ 0.8, 1.0],\n",
    "        \"n_estimators\":[5,10]\n",
    "            }\n",
    "\n",
    "            clf = GridSearchCV(GradientBoostingRegressor(), parameters, cv=3, n_jobs=-1)\n",
    "\n",
    "            clf.fit(X_train, y_train)\n",
    "            print(clf.score(X_train, y_train))\n",
    "            print(clf.best_params_)\n",
    "\n",
    "        #correct_test = correct_data(test)\n",
    "        #testX = correct_test[predictor].values\n",
    "            result = clf.predict(X_test)\n",
    "            \n",
    "            df_imporatnce=pd.DataFrame({\"tag\":unique_sequences, \"importance\":clf.best_estimator_.feature_importances_})\n",
    "            df_imporatnce=df_imporatnce.loc[df_imporatnce['importance'] > 0]\n",
    "            df_imporatnce.to_csv(\"/Users/moradigd/Documents/Plasmid/importance\"+str(g)+'_'+str(m)+'_'+str(df_input.columns[2]))\n",
    "            print(df_imporatnce)\n",
    "\n",
    "    \n",
    "            from scipy import stats\n",
    "            rho, pval = stats.spearmanr(result, y_test)\n",
    "            print(rho)\n",
    "            print(pval)\n",
    "            print(df_input.shape)\n",
    "            print(df_input.columns)\n",
    "            result_f.append([rho,pval, g, df_input.columns[2], 'gb',m])\n",
    "        \n",
    "        \n",
    "        \n",
    "            from sklearn.linear_model import LassoCV\n",
    "        #reg = LassoCV(cv=3, random_state=0).fit(X_train, y_train)\n",
    "        \n",
    "            lasso = Lasso(random_state=0, max_iter=10000)\n",
    "            alphas = np.logspace(-4, -0.5, 10)\n",
    "    \n",
    "            tuned_parameters = [{'alpha': alphas}]\n",
    "            clf = GridSearchCV(lasso, tuned_parameters, cv=3)\n",
    "            clf.fit(X_train, y_train)\n",
    "            print(clf.best_params_)\n",
    "            result = clf.predict(X_test)\n",
    "\n",
    "    \n",
    "            from scipy import stats\n",
    "            rho, pval = stats.spearmanr(result, y_test)\n",
    "            print(rho)\n",
    "            print(pval)\n",
    "            print(df_input.shape)\n",
    "            print(df_input.columns)\n",
    "            result_f.append([rho,pval, g, df_input.columns[2], 'lasso',m])\n",
    "            \n",
    "            pd.DataFrame(result_f).to_csv(\"/Users/moradigd/Documents/Plasmid/results_screening_agg_scale.csv\")\n",
    "        \n",
    "        #model = XGBRegressor()\n",
    "        #model.fit(X[0:int(df_input.shape[0]*0.8) , :] , y[0:int(df_input.shape[0]*0.8) ])\n",
    "        #model.predict(X[int(df_input.shape[0]*0.8) :df_input.shape[0], :])\n",
    "\n",
    "        #mp.scatter(model.predict(X[int(df_input.shape[0]*0.8) :df_input.shape[0], :]), y[int(df_input.shape[0]*0.8) :df_input.shape[0]])\n",
    "        #mp.xlabel('array1')\n",
    "        #mp.ylabel('array2')\n",
    "        #from scipy import stats\n",
    "        #rho, pval = stats.spearmanr(model.predict(X[int(df_input.shape[0]*0.8) :df_input.shape[0], :]), y[int(df_input.shape[0]*0.8) :df_input.shape[0]])\n",
    "        #print(rho)\n",
    "        #print(pval)\n",
    "        #print(df_input.shape)\n",
    "        #print(df_input.columns)\n",
    "        #result.append([rho,pval, g, df_input.columns[2]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_sequences_freq.to_csv(\"/Users/moradigd/Documents/Plasmid/interval.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_sequences_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as mp\n",
    "from numpy import absolute\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "result_f=[]\n",
    "label_index=2\n",
    "for k in range(2,4):\n",
    "    import pandas as pd\n",
    "    df_input=pd.read_csv(\"/Users/moradigd/Documents/Plasmid/input_agg.csv\")\n",
    "    df_input.columns\n",
    "    df_input=df_input.iloc[:,[0,k]]\n",
    "    df_input.shape\n",
    "    df_input=df_input.dropna()\n",
    "    df_input=df_input.reset_index()\n",
    "    unique_sequences_agg=[]\n",
    "    df_sequences_agg= pd.DataFrame()\n",
    "     \n",
    "    for g in range(5,7):\n",
    "        \n",
    "        print(\"start\")\n",
    "        unique_sequences_set=[]\n",
    "#for i in range(len(df_input['seq'])):\n",
    "\n",
    "        for i in range(df_input.shape[0]):\n",
    "            unique_sequences_set=unique_sequences_set+getKmers(df_input['seq'][i], g, 1)\n",
    "        unique_sequences=list(set(unique_sequences_set))\n",
    "        unique_sequences_agg=unique_sequences_agg+unique_sequences\n",
    "\n",
    "        print(\"done\")\n",
    "#\"abcdabcva\".count(\"ab\")\n",
    "#df_input['seq'][1].count(unique_sequences[1])\n",
    "\n",
    "        [df_input['seq'][1].count(i) for i in unique_sequences]\n",
    "        \n",
    "        print(\"start\")\n",
    "        unique_sequences_freq=[]\n",
    "#for i in range(len(df_input['seq'])):\n",
    "        for j in range(df_input.shape[0]):\n",
    "            unique_sequences_freq.append([df_input['seq'][j].count(i) for i in unique_sequences])\n",
    "        unique_sequences_freq   \n",
    "        unique_sequences_freq=pd.DataFrame(unique_sequences_freq)\n",
    "#unique_sequences_freq.columns=unique_sequences\n",
    "        unique_sequences_freq\n",
    "    \n",
    "        #df_sequences_agg= pd.concat([df_sequences_agg,unique_sequences_freq])\n",
    "        #InfoDF = pd.concat([InfoDF,tempDF])\n",
    "        print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unique_sequences_agg)\n",
    "#len(unique_sequences)\n",
    "df_sequences_agg.shape\n",
    "#unique_sequences_freq.shape\n",
    "df_sequences_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_sequences_freq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_sequences_freq_t=unique_sequences_freq.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_sequences_freq_t.columns=['seq'+str(i) for i in range(unique_sequences_freq_t.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_sequences_freq_t.index=unique_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_sequences_freq_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros((unique_sequences_freq_t.shape[0],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[\"Non-unique Gene name\",\"Annotation\",\"No. isolates\",\"No. sequences\",\"Avg sequences per isolate\",\"Genome Fragment\",\"Order within Fragment\",\"Accessory Fragment\",\"Accessory Order with Fragment\",\"QC\",\"Min group size nuc\",\"Max group size nuc\",\"Avg group size nuc\"]\n",
    "unique_sequences_freq_left=pd.DataFrame(np.zeros((unique_sequences_freq_t.shape[0],len(labels))), columns=labels, index= unique_sequences)\n",
    "len(labels)\n",
    "\n",
    "unique_sequences_freq_left=unique_sequences_freq_left.join(unique_sequences_freq_t)\n",
    "unique_sequences_freq_left.index.names = ['Gene'] \n",
    "unique_sequences_freq_left.reset_index(level=0, inplace=True)\n",
    "unique_sequences_freq_left.to_csv(\"/Users/moradigd/Documents/Plasmid/pan_genome_PB_1.csv\", index=False)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_sequences_freq_left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.empty((unique_sequences_freq_t.shape[0],len(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for k in range(2,4):\n",
    "    import pandas as pd\n",
    "    df_input=pd.read_csv(\"/Users/moradigd/Documents/Plasmid/input_agg.csv\")\n",
    "    \n",
    "    df_input=df_input.iloc[:,[0,k]]\n",
    "    \n",
    "    df_input=df_input.dropna()\n",
    "    df_input=df_input.reset_index()\n",
    "    \n",
    "    print(df_input.columns)\n",
    "    print(df_input.shape)\n",
    "    \n",
    "    unique_sequences_set_agg= pd.DataFrame(index=np.arange(df_input.shape[0]))\n",
    "    unique_sequences_agg=[]\n",
    "    \n",
    "    for g in range(5,20,2):\n",
    "        print(g)\n",
    "        unique_sequences_set=[]\n",
    "#for i in range(len(df_input['seq'])):\n",
    "        for i in range(df_input.shape[0]):\n",
    "            unique_sequences_set=unique_sequences_set+getKmers(df_input['seq'][i], g, 1)\n",
    "        unique_sequences=list(set(unique_sequences_set))\n",
    "        unique_sequences_agg=unique_sequences_agg+unique_sequences\n",
    "\n",
    "        [df_input['seq'][1].count(i) for i in unique_sequences]\n",
    "\n",
    "        unique_sequences_freq=[]\n",
    "#for i in range(len(df_input['seq'])):\n",
    "        for j in range(df_input.shape[0]):\n",
    "            unique_sequences_freq.append([df_input['seq'][j].count(i) for i in unique_sequences])\n",
    "        unique_sequences_freq   \n",
    "        unique_sequences_freq=pd.DataFrame(unique_sequences_freq)\n",
    "#unique_sequences_freq.columns=unique_sequences\n",
    "        #unique_sequences_freq.columns=['g_'+str(g)+'_'+str(x) for x in unique_sequences_freq.columns]\n",
    "        unique_sequences_freq.columns=unique_sequences\n",
    "        unique_sequences_set_agg=unique_sequences_set_agg.join(unique_sequences_freq)\n",
    "        print(unique_sequences_set_agg.shape)\n",
    "        \n",
    "    unique_sequences_freq_t=unique_sequences_set_agg.transpose()\n",
    "    unique_sequences_freq_t.columns=['seq'+str(i) for i in range(unique_sequences_freq_t.shape[1])]\n",
    "    unique_sequences_freq_t.index=unique_sequences_agg\n",
    "        \n",
    "        \n",
    "    labels=[\"Non-unique Gene name\",\"Annotation\",\"No. isolates\",\"No. sequences\",\"Avg sequences per isolate\",\"Genome Fragment\",\"Order within Fragment\",\"Accessory Fragment\",\"Accessory Order with Fragment\",\"QC\",\"Min group size nuc\",\"Max group size nuc\",\"Avg group size nuc\"]\n",
    "    unique_sequences_freq_left=pd.DataFrame(np.zeros((unique_sequences_freq_t.shape[0],len(labels))), columns=labels, index= unique_sequences_agg)\n",
    "    len(labels)\n",
    "\n",
    "    unique_sequences_freq_left=unique_sequences_freq_left.join(unique_sequences_freq_t)\n",
    "    unique_sequences_freq_left.index.names = ['Gene'] \n",
    "    unique_sequences_freq_left.reset_index(level=0, inplace=True)\n",
    "    print(unique_sequences_freq_left.shape)\n",
    "    unique_sequences_freq_left.to_csv(\"/Users/moradigd/Documents/Plasmid/pan_genome_agg_\"+df_input.columns[2]+\".csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_sequences_set_agg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unique_sequences_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_sequences_freq_t=unique_sequences_set_agg.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_sequences_freq_t.columns=['seq'+str(i) for i in range(unique_sequences_freq_t.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processor(label=\"labels\"):\n",
    "    file_input=open('/Users/moradigd/Documents/streamlit/input.fasta', 'r')\n",
    "    labels=[]\n",
    "    sequences=[]\n",
    "\n",
    "    for i in file_input.readlines():\n",
    "        if \">\" in i:\n",
    "            labels.append(i.replace(\">\", \"\").replace('\\n', ''))\n",
    "        else:\n",
    "            sequences.append(i.replace('\\n', ''))\n",
    "    if label==\"labels\":\n",
    "        return labels\n",
    "    elif label==\"sequence\":\n",
    "        return sequences\n",
    "processor(label=\"sequence\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[\"Non-unique Gene name\",\"Annotation\",\"No. isolates\",\"No. sequences\",\"Avg sequences per isolate\",\"Genome Fragment\",\"Order within Fragment\",\"Accessory Fragment\",\"Accessory Order with Fragment\",\"QC\",\"Min group size nuc\",\"Max group size nuc\",\"Avg group size nuc\"]\n",
    "unique_sequences_freq_left=pd.DataFrame(np.zeros((unique_sequences_freq_t.shape[0],len(labels))), columns=labels, index= unique_sequences_agg)\n",
    "len(labels)\n",
    "\n",
    "#unique_sequences_freq_t.index=unique_sequences\n",
    "\n",
    "unique_sequences_freq_left=unique_sequences_freq_left.join(unique_sequences_freq_t)\n",
    "unique_sequences_freq_left.index.names = ['Gene'] \n",
    "unique_sequences_freq_left.reset_index(level=0, inplace=True)\n",
    "unique_sequences_freq_left.to_csv(\"/Users/moradigd/Documents/Plasmid/pan_genome_PB_1.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_sequences_freq_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input.columns[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_sequences_freq_left.to_csv(\"/Users/moradigd/Documents/Plasmid/pan_genome_\"+df_input.columns[2]+\".csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_sequences_freq_left=unique_sequences_freq_left.join(unique_sequences_freq_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Isolation forests morphology\n",
    "import pandas as pd\n",
    "input_df=pd.read_csv(\"/Users/moradigd/Documents/chemicalgenomic/similarity_morphology.csv\", index_col=0)\n",
    "input_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df.head\n",
    "input_df_red=input_df\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "clf=IsolationForest(n_estimators=100, max_samples='auto', contamination=float(.12), max_features=1.0, bootstrap=False, n_jobs=-1, random_state=42, verbose=0)\n",
    "clf.fit(input_df_red)\n",
    "pred = clf.predict(input_df_red)\n",
    "pred\n",
    "\n",
    "\n",
    "input_df_red['anomaly']=pred\n",
    "outliers=input_df_red.loc[input_df_red['anomaly']==-1]\n",
    "outlier_index=list(outliers.index)\n",
    "#print(outlier_index)\n",
    "#Find the number of anomalies and normal points here points classified -1 are anomalous\n",
    "print(input_df_red['anomaly'].value_counts())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "input_df=pd.read_csv(\"/Users/moradigd/Documents/chemicalgenomic/similarity_colony_circularity.csv\")\n",
    "input_df\n",
    "\n",
    "range_cont=np.arange(0.01,0.5,0.05)\n",
    "for i in range(len(range_cont)):\n",
    "    import pandas as pd\n",
    "    input_df=pd.read_csv(\"/Users/moradigd/Documents/chemicalgenomic/similarity_colony_circularity.csv\")\n",
    "    input_df_red=input_df\n",
    "    print(i)\n",
    "    clf=IsolationForest(n_estimators=100, max_samples='auto', contamination=float(range_cont[i]), max_features=1.0, bootstrap=False, n_jobs=-1, random_state=42, verbose=0)\n",
    "    clf.fit(input_df_red)\n",
    "    pred = clf.predict(input_df_red)\n",
    "\n",
    "    input_df_red['anomaly']=pred\n",
    "    outliers=input_df_red.loc[input_df_red['anomaly']==-1]\n",
    "    outlier_index=list(outliers.index)\n",
    "    print(input_df_red['anomaly'].value_counts())\n",
    "    pd.DataFrame({\"names\":input_df_red.columns[:-1], \"anomaly\":pred}).to_csv(\"/Users/moradigd/Documents/chemicalgenomic/anomaly_circularity_labels\"+str(i)+\".csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy \n",
    "numpy.version.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.DataFrame({\"names\":input_df_red.columns[:-1], \"anomaly\":pred}).to_csv(\"/Users/moradigd/Documents/chemicalgenomic/anomaly_labels.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(0.01,0.5,0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "pca = PCA(n_components=3)  # Reduce to k=3 dimensions\n",
    "scaler = StandardScaler()\n",
    "\n",
    "to_model_columns=input_df_red.columns[1:13]\n",
    "#normalize the metrics\n",
    "X = scaler.fit_transform(input_df_red[to_model_columns])\n",
    "X_reduce = pca.fit_transform(X)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.set_zlabel(\"x_composite_3\")\n",
    "# Plot the compressed data points\n",
    "ax.scatter(X_reduce[:, 0], X_reduce[:, 1], zs=X_reduce[:, 2], s=4, lw=1, label=\"inliers\",c=\"green\")\n",
    "# Plot x's for the ground truth outliers\n",
    "ax.scatter(X_reduce[outlier_index,0],X_reduce[outlier_index,1], X_reduce[outlier_index,2],\n",
    "           lw=2, s=60, marker=\"x\", c=\"red\", label=\"outliers\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "df = input_df_red\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "components = pca.fit_transform(input_df_red)\n",
    "labels = input_df_red['anomaly']\n",
    "\n",
    "fig = px.scatter(components, x=0, y=1, color=labels)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "exp_var_cumul = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "px.area(\n",
    "    x=range(1, exp_var_cumul.shape[0] + 1),\n",
    "    y=exp_var_cumul,\n",
    "    labels={\"x\": \"# Components\", \"y\": \"Explained Variance\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "input_df=pd.read_csv(\"/Users/moradigd/Documents/chemicalgenomic/similarity_morphology_matrix.csv\")\n",
    "input_df\n",
    "input_df_red=input_df\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "clf=IsolationForest(n_estimators=100, max_samples='auto', contamination=float(.5), max_features=1.0, bootstrap=False, n_jobs=-1, random_state=42, verbose=0)\n",
    "clf.fit(input_df_red)\n",
    "pred = clf.predict(input_df_red)\n",
    "pred\n",
    "\n",
    "\n",
    "input_df_red['anomaly']=pred\n",
    "outliers=input_df_red.loc[input_df_red['anomaly']==-1]\n",
    "outlier_index=list(outliers.index)\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "time_start = time.time()\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=20, n_iter=300)\n",
    "tsne_results = tsne.fit_transform(input_df_red)\n",
    "print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "input_df_red['tsne-2d-one'] = tsne_results[:,0]\n",
    "input_df_red['tsne-2d-two'] = tsne_results[:,1]\n",
    "input_df_red['y'] =input_df_red['anomaly']\n",
    "plt.figure(figsize=(16,10))\n",
    "scatter=sns.scatterplot(\n",
    "    x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n",
    "    hue=\"y\",\n",
    "    palette=sns.color_palette(\"hls\", 2),\n",
    "    data=input_df_red,\n",
    "    legend=\"full\",\n",
    "    alpha=0.3\n",
    ")\n",
    "\n",
    "scatter.set_xlim(left=-35, right=35)\n",
    "scatter.set_ylim(bottom=-35, top=35)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "time_start = time.time()\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "tsne_results = tsne.fit_transform(input_df_red)\n",
    "print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "input_df_red['tsne-2d-one'] = tsne_results[:,0]\n",
    "input_df_red['tsne-2d-two'] = tsne_results[:,1]\n",
    "input_df_red['y'] =input_df_red['anomaly']\n",
    "plt.figure(figsize=(16,10))\n",
    "scatter=sns.scatterplot(\n",
    "    x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n",
    "    hue=\"y\",\n",
    "    palette=sns.color_palette(\"hls\", 2),\n",
    "    data=input_df_red,\n",
    "    legend=\"full\",\n",
    "    alpha=0.3\n",
    ")\n",
    "\n",
    "scatter.set_xlim(left=-35, right=35)\n",
    "scatter.set_ylim(bottom=-35, top=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Image\n",
    "import cv2\n",
    "img1 = cv.imread('ml.png')\n",
    "img2 = cv.imread('opencv-logo.png')\n",
    "dst = cv.addWeighted(img1,0.7,img2,0.3,0)\n",
    "cv.imshow('dst',dst)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img1 = cv2.imread('/Users/moradigd/Documents/chemicalgenomic/morphology/image_output_PA14_18630.jpg')\n",
    "img2 = cv2.imread('/Users/moradigd/Documents/chemicalgenomic/morphology/image_output_PA14_18640.jpg')\n",
    "dst = cv2.addWeighted(img1,0.5,img2,0.5,0)\n",
    "cv2.imshow('dst',dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "files=glob.glob(\"/Users/moradigd/Documents/chemicalgenomic/morphology/test/*\")\n",
    "img1 = cv2.imread(files[0])\n",
    "img2 = cv2.imread(files[1])\n",
    "\n",
    "dst = cv2.addWeighted(img1,0.5,img2,0.5,0)\n",
    "\n",
    "for i in range(2,4):\n",
    "    img_tmp = cv2.imread(files[i])\n",
    "    dst = cv2.addWeighted(dst,i/(i+1),img_tmp,1/(i+1),0)\n",
    "    print(i)\n",
    "\n",
    "import pandas as pd\n",
    "df=pd.read_csv(\"/Users/moradigd/Documents/chemicalgenomic/df_clustering_similarity_morphology_shortened.csv\")\n",
    "isolates=df.isolate[df.cluster==6].values\n",
    "isolates_list=[\"/Users/moradigd/Documents/chemicalgenomic/morphology/image_output_\"+i+\".jpg\" for i in isolates]\n",
    "isolates_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "df=pd.read_csv(\"/Users/moradigd/Documents/chemicalgenomic/df_clustering_similarity_colour.csv\")\n",
    "isolates=df.isolate[df.cluster==9].values\n",
    "files=[\"/Users/moradigd/Documents/chemicalgenomic/morphology/image_output_\"+i+\".jpg\" for i in isolates]\n",
    "\n",
    "#files=glob.glob(\"/Users/moradigd/Documents/chemicalgenomic/morphology/test/*\")\n",
    "\n",
    "img1 = cv2.imread(files[0])\n",
    "img2 = cv2.imread(files[1])\n",
    "\n",
    "dst = cv2.addWeighted(img1,0.5,img2,0.5,0)\n",
    "\n",
    "#for i in range(2,len(files)):\n",
    "for i in range(2,6):\n",
    "    print(i)\n",
    "    img_tmp = cv2.imread(files[i])\n",
    "    dst = cv2.addWeighted(dst,i/(i+1),img_tmp,1/(i+1),0)\n",
    "\n",
    "cv2.imshow('dst',dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imread(files[1])\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.addWeighted(dst,i/(i+1),img_tmp,1/(i+1),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a6a1e0beb5c4093c68379d44901e3bf8cc001d206d28c8b48ff62f1c3d14f6f5"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
